{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAPS_DNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yNxO45Q-cZ_"
      },
      "outputs": [],
      "source": [
        "def pprint(arr):\n",
        "    print(\"type:{}\".format(type(arr)))\n",
        "    print(\"shape: {}, dimension: {}, dtype:{}\".format(arr.shape, arr.ndim, arr.dtype))\n",
        "    print(\"Array's Data:\\n\", arr)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load input data\n",
        "# data = pd.read_csv(\"Dataframe_l1_special.csv\")\n",
        "#data = pd.read_csv(\"2_8.csv\")\n",
        "data = pd.read_csv(\"1_1_10p.csv\")\n",
        "data = data.values\n",
        "N    = 10000\n",
        "\n",
        "np.random.shuffle(data)\n",
        "\n",
        "# Make training data balanced & Shuffle \n",
        "data1 = data[0:N,:]\n",
        "data2 = data[N:2*N,:]\n",
        "data3 = data[2*N:3*N,:]\n",
        "data4 = data[3*N:4*N,:]\n",
        "data5 = data[4*N:5*N,:]\n",
        "data6 = data[5*N:6*N,:]\n",
        "data7 = data[6*N:7*N,:]\n",
        "data8 = data[7*N:8*N,:]\n",
        "data9 = data[8*N:9*N,:]\n",
        "data10 = data[9*N:10*N,:]\n",
        "\n",
        "np.random.shuffle(data1)\n",
        "np.random.shuffle(data2)\n",
        "np.random.shuffle(data3)\n",
        "np.random.shuffle(data4)\n",
        "np.random.shuffle(data5)\n",
        "np.random.shuffle(data6)\n",
        "np.random.shuffle(data7)\n",
        "np.random.shuffle(data8)\n",
        "np.random.shuffle(data9)\n",
        "np.random.shuffle(data10)\n",
        "\n",
        "\n",
        "N_train = round(0.7*N)\n",
        "N_val   = round(0.1*N)\n",
        "\n",
        "\n",
        "data_train = np.concatenate((data1[0:N_train,:],data2[0:N_train,:],data3[0:N_train,:],data4[0:N_train,:],data5[0:N_train,:],data6[0:N_train,:],data7[0:N_train,:],data8[0:N_train,:],data9[0:N_train,:],data10[0:N_train,:]), axis=0)\n",
        "data_val   = np.concatenate((data1[N_train:(N_train+N_val),:],data2[N_train:(N_train+N_val),:],data3[N_train:(N_train+N_val),:],data4[N_train:(N_train+N_val),:],data5[N_train:(N_train+N_val),:],data6[N_train:(N_train+N_val),:],data7[N_train:(N_train+N_val),:],data8[N_train:(N_train+N_val),:],data9[N_train:(N_train+N_val),:],data10[N_train:(N_train+N_val),:]), axis=0)\n",
        "data_test  = np.concatenate((data1[(N_train+N_val):N,:],data2[(N_train+N_val):N,:],data3[(N_train+N_val):N,:],data4[(N_train+N_val):N,:],data5[(N_train+N_val):N,:],data6[(N_train+N_val):N,:],data7[(N_train+N_val):N,:],data8[(N_train+N_val):N,:],data9[(N_train+N_val):N,:],data10[(N_train+N_val):N,:]), axis=0)\n",
        "\n",
        "x_train = data_train[:,0:140]\n",
        "y_train = data_train[:,142]\n",
        "x_val   = data_val[:,0:140]\n",
        "y_val   = data_val[:,142]\n",
        "x_test  = data_test[:,0:140]\n",
        "y_test  = data_test[:,142]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import sparse_top_k_categorical_accuracy\n",
        "from keras import optimizers\n",
        "\n",
        "def plot_history(histories):    \n",
        "    plt.figure(figsize=(8,6))    \n",
        "    for name, history in histories:\n",
        "        val = plt.plot(history.epoch, history.history['val_sparse_categorical_accuracy'], '--', label=name+' (Validation)')\n",
        "        plt.plot(history.epoch, history.history['sparse_categorical_accuracy'], color=val[0].get_color(), label=name+' (Train)') \n",
        "        \n",
        "        val = plt.plot(history.epoch, history.history['val_top2_acc'], 'r--', label=name+' Top 2 (Validation)')\n",
        "        plt.plot(history.epoch, history.history['top2_acc'], color=val[0].get_color(), label=name+' Top 2 (Train)')        \n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.xlim([0, max(history.epoch)])\n",
        "    plt.grid()\n",
        "    \n",
        "def top2_acc(y_true, y_pred):\n",
        "    return sparse_top_k_categorical_accuracy(y_true, y_pred, k=2) \n",
        "    \n",
        "# Train Phase\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(140, activation=tf.nn.selu, input_shape=(140,),\n",
        "                       kernel_initializer='he_normal', bias_initializer='he_normal',\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(110, activation=tf.nn.selu,\n",
        "                       kernel_initializer='he_normal', bias_initializer='he_normal',\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),   \n",
        "    keras.layers.Dense(80, activation=tf.nn.selu,\n",
        "                       kernel_initializer='he_normal', bias_initializer='he_normal',\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(60, activation=tf.nn.selu,\n",
        "                       kernel_initializer='he_normal', bias_initializer='he_normal',\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(43, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "\n",
        "# Optimizer\n",
        "adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.0, nesterov=True)\n",
        "model.compile(optimizer = adam,\n",
        "             loss       = 'sparse_categorical_crossentropy',\n",
        "             metrics    = ['sparse_categorical_accuracy',top2_acc])\n",
        "\n",
        "model.summary()\n",
        "model_history = model.fit(x_train, y_train,\n",
        "                          epochs          = 500,\n",
        "                          batch_size      = 128,\n",
        "                          validation_data = (x_val,y_val),\n",
        "                          verbose         = 0)\n",
        "\n",
        "plot_history([('mMAPS', model_history)])\n",
        "\n",
        "# Test Phase\n",
        "test_loss, test_acc, test_top2acc = model.evaluate(x_test, y_test)\n",
        "print('Test Accuracy:', test_acc)\n",
        "print('Test Top-2 Accuracy:', test_top2acc)"
      ],
      "metadata": {
        "id": "GTyKnJ0TDPuh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}